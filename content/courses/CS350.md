---
title: "CS350 - Operating Systems"
url: "courses/CS350/"
summary: An introduction to the fundamentals of operating system function, design, and implementation
ShowToc: true
math: true
---

> **Instructor:** Rob Hackman \
> **Lectures:** T/Th at 10:00am \
> **Section:** 001 \
> \
> **Course Breakdown:** \
> Assignments: 2%, 12%, 11%, 15% \
> Reading Assignments: 2 $\times$ 5% \
> Midterm: 1 $\times$ 20% \
> Final Exam: 1 $\times$ 30% \
> \
> **Course Description:** \
> An introduction to the fundamentals of operating system function, design, and implementation. Topics include concurrency, synchronization, processes, threads, scheduling, memory management, file systems, device management, and security.

 

# Introduction

## Motivation
How do multiple programs run at the same time and utilize computer resources? The "middle man" responsible for this is the Operating System (OS). This is a maturing field and many different computer science topics are OS issues (high-performance servers, resource consumption, security, databases, game engines, etc.)

We will learn the basics of operating systems, what they do, what issues they can face, and how they affect software. Some key concepts include multi-programming, concurrency, memory management, device management, and file systems. We will focus on these concepts with an emphasis on security and protection. 


## What is an Operating System?

The operating system (OS) is a layer between applications and hardware that provides an **abstraction** to the hardware details and program resources, allowing programmers to interact with hardware securely and effectively. It contains a kernel that responds to system calls, interrupts, and exceptions.

Originally, they were just a library of standard services that didn't really offer any security and the system could only run one program at a time. However, 
multitasking capabilities were then realized to make it appear as though multiple programs are running at the same time to allow for concurrency. More features were eventually added, leading to a prototype of a modern OS.

### Views of an OS

1. **Application View**:

    The OS provides an execution environment for running programs. This environment provides us with an interface to access networks, storage, I/O devices, as well as enables programs to run alongside other programs with the appropriate protections.

2. **System View**:

    The OS manages the hardware resources of a computer system. It allocates the required resources for programs to run and controls how they are shared. Such resources includes processors, memory, disks, storage devices, networks, and I/O devices.

3. **Implementation View**:

    The OS is a concurrent, real-time program where it needs to run alongside other programs and must respond to events with specific timing constraints.

### How does the OS protect us?

1. **Preemption**:

    Give applications a resource, take it away if needed elsewhere

2. **Interposition**:

     Place the OS between application and "stuff", track all pieces that application allowed to use, and on every access, look in table to check that access legal

3. **(Un)privileged Modes**:

     Applications are unprivileged and the OS is privileged - system calls can only be done in privileged mode

### System Calls

If we have to perform system calls (unprivileged to privileged), then special instructions will invoke a `syscall` handler which stores the state of the registers, loads into the program counter a predetermined address in the kernel memory (enabling privileged mode), then returns back to the original application (disabling privileged mode).

We want to perform system calls if our application needs to do things that it cannot do in unprivileged mode. Higher-level functions such as `printf`, `gets`, `scanf`, etc. are built upon the `syscall` interface.

### Schematic of the OS

Below, we have a schematic of the OS:

<center>
<img src="/cs350-os-example.png" width="550" height="350" alt="OS Schematic">
</center>

 Note that the user programs here would be unprivileged, and that the program needs to interact with the kernel in order to run in privileged mode and access hardware.








 

# Processes and Threads

The OS provides processes, threads, locks, and file I/O to applications. Let's focus on the process and thread abstraction first.

## Introduction

**Process:** An instance of a running program

**Thread:** A sequence of scheduled executions

The OS keeps track of processes using a data structure which includes execution details such as running threads, address space, open files, and more. Each process has their own unique process ID (PID) and will always have at least one thread (the program entry point).

The OS enables multiple processes to run, increasing CPU utilization and reducing latency. Most programs do not care which other programs are running, but not all programs (we will see how to deal with this later).

Here are the states of a process/thread:

* Running $\rightarrow$ Blocked: Asks for a resource that is not available
* Blocked $\rightarrow$  Ready: Resource becomes available
* Ready $\rightarrow$  Running: When the OS schedules it (core is available)
* Running $\rightarrow$  Ready: Yielding or preemption

<center>
<img src="/cs350-process-states.png" width="550" height="250" alt="Process States">
</center>

Whenever a thread stalls for input, another thread will execute on the CPU core until input has been received (moving the thread into a ready state) AND the other thread has been kicked off by the OS. A nice real-life analogy to this is sharing equipment with someone on an fixed ON/OFF cycle.


## User View of Processes

### `int fork (void)`:

1. **Description**:

    Creates a new process that is a (near) exact copy of the current one

2. **Return Values**:

    - `pid` of the new process in "parent" process after the fork
    - `0` in the "child" process after the fork

3. **Example Usage**:

    ```c
    #include <unistd.h>
    #include <sys/wait.h>

    switch (pid = fork()) {    // we check the return value of fork()
        case -1:
            perror("fork"); break;
        case 0:
            // do something in child process
        default:
            // do something in parent process
    }
    ```

4. **Other Notes**:

    We would like to use forks in cases where we might want to have parallelism (Nginx, PostgreSQL, etc.). It is very simple to deal with as there are no arguments, and we can use the child to perform any different tasks like manipulate file descriptors, environment, and set resource limits. Note that the processes are independent, so they have their own memory.  

 

### `int waitpid (int pid, int *stat, int opt)`:

1. **Description**:

    Suspends execution of the calling process until the process indicated by `pid` has changed state (ends or is stopped)

2. **Arguments**:

    - `pid`: Process to wait for, or -1 for any
    - `stat`: The exit value or signal
    - `opt`: Usually `0` or `WNOHANG`

3. **Return Values**:

    - `pid` if successful, otherwise `-1`

4. **Example Usage**:

    ```c
    #include <unistd.h>
    #include <stdio.h>
    #include <sys/wait.h>

    int main() {
        int rc1, rc2, rc3;
        rc1 = fork();
        rc2 = fork();
        rc3 = fork();
        int exit_status;
        printf("1");                      // This gets printed 8 times!
        waitpid(rc1, &exit_status, 0);
        waitpid(rc2, &exit_status, 0);
        waitpid(rc3, &exit_status, 0);
    }
    ```

5. **Additional Notes**:

    - We use this function if and only if we need to wait for a *child* process to finish execution to continue executing. This should always be used if a process is being forked so all children processes are finished before the parent process can finish.

    - If a process exits but its parent is still alive, then we must store the exit code status somehow. The best way to approach this is to destroy its information but leave the data structures available and leave an exit code.

    - You can only free processes when waitpid is called on it or when its parent exits (you need to check all the children in this case).

    - If process A creates process B and process A exits, then process B should **not** be killed. However, when process B returns, then it needs to check if its parents is alive, and if not, then process B is responsible for cleaning itself up.


 

### `void exit (int status)`:

$\hspace{0.5cm}$ Closes the current process and passes `status` to its parent (usually through `waitpid`) for it to use as it wishes.

 

### `int kill (int pid, int sig)`:

1. **Description**:

    Sends `sig` to a process `pid` to forcibly interrupt that process

2. **Arguments**:

    - `pid`: The pid of the process we want to interrupt
    - `sig`: The signal we wish to send to the process

3. **Return Values**:

    - `0` if successful, otherwise `-1`


 


### `int execve(char *prog, char **argv, char **envp)`:

1. **Description**:

    Executes a specified program (`prog`) and passes the provided command-line arguments and environment variables.

2. **Arguments**:

    - `prog`: Full pathname of program to run
    - `argv`: Argument vector that gets passed to main
    - `envp`: Environment variables (eg. `PATH`, `HOME`)

3. **Return Values**:

    - `execve` should not return any values

4. **Example Usage**:

    ```c
    #include <sys/wait.h>
    #include <errno>

    int main(int argc, char **argv) {
        int rc = fork();
        if (rc == 0) {
            char *args[] = {"grep", argv[1], "alice.txt", NULL};
            execvp("grep", args);
            printf("Execv error code: %d\n", x);
            printf("Execv errno: %d\n", errno);
        }
        int status;
        waitpid(rc, &status, 0);
        if (WEXITSTATUS(status) == 0) {
            printf("Word %s was found \n", argv[1]);
        } else {
            printf("Word %s was not found \n", argv[1]);
        }
    }
    ```

5. **Additional Notes**:

    - This does not create a new process - it changes the identity of the program instead. Therefore, it should only be used on a child process
    - There are variants of this function (`execvp` and `exevlp`) that have similar functionality to `execve` but with some small differences - these will not be covered individually

 

### `int dup2 (int oldfd, int newfd)`

The following functions in this subsection concerns file descriptors which can be thought of as an open cursor to a file - part of the data of the file is stored. Opening a file is also an OS task.

This command will close `newfd` if it was a valid descriptor and makes `newfd1` an exact copy of `oldfd`. Two file descriptors will share the same offset.

Note that `dup2(x, 0)` will change `x`'s file descriptor to `stdin` and `dup2(x, 1)` will change `x`'s file descriptor to `stdout`.

### `int fcntl (int fd, F_SETFD, int val)`

This will set the `close on exec` if `val = 1` and clears if `val = 0`. The file descriptor will be made non-inheritable by the new program.

### `int pipe (int fds[2])`

This will return two file descriptors in `fds[0]` and `fds[1]`. Any writes to `fds[1]` will be read on `fds[0]`, and when the last copy of `fds[1]` is closed, then `fds[0]` will return `EOF`. It will return `0` on success and `-1` on error.

Pipes can read, write, and close just like with files. If `fds[1]` is closed, then `read(fds[0])` will return 0 bytes. When `fds[0]` is closed, then `write(fds[1])` and we kill the process.


 

## Kernel View of Processes

### Implementation

The OS keeps a data structure for each proc (Process Control Block). It will track the information necessary for each process to run, which includes:
* Process State and Process ID
* Registers and Program Counter
* Address Space
* Open Files

If a process is forked, the parent and child processes will share the same address space, but they will not share memory.

### User and Kernel Modes

A key component of an operating system is to introduce restrictions on what a process can do for safety purposes (I/O, device connection, create new processes, etc.). The way the OS does this is to have a **user mode** (unprivileged) and a **kernel mode** (privileged).

Because our own programs may need to execute privileged instructions, the kernel will provide the ability to perform system calls.

How this works is that the program will execute a `trap` instruction which sends a signal to the OS to switch to kernel mode and executes the appropriate kernel code.  Then once this kernel code is executed, the OS calls a `return-from-trap` instruction that returns to user mode and continues executing the original program.

To ensure that the proper code is executed, the kernel needs to set up a trap table that tells the hardware what code to run when certain signals are received.

<center>
<img src="/cs350-trap-example.png" width="500" height="600" alt="Trap Example">
</center>





### Preemption

We can preempt (interrupt) a process when the kernel gets control. If there is such an interrupt (scheduling quantum, device recognition, etc.), then we need to save the state of the process/thread before the kernel can run its code. This is what is known as context-switching. We can use a switch statement to understand the content of the interrupt, of which the appropriate kernel code will be executed.
\
The CPU has a clock of which we can set up a timer to perform interrupts.

Whenever a process is interrupted, it will save:
1. The program counter and integer registers (always)
2. Special registers and floating points
3. Condition codes

<center>
<img src="/cs350-switch-example.png" width="500" height="500" alt="Switch Example">
</center>


then possibly change virtual address translations. We can then see that context switching is expensive and can cause TLB flushes as well as cache misses.

When process 1's thread gets preempted, then the following calls occur on its stack:

Thread data $\to$ Trap Frame $\to$ MIPS trap (general) $\to$ mainbus_interrupt (specific) $\to$ thread_switch $\to$ switchframe_switch

Switch frames are just the special registers, and when we call `switchframe_switch`, its returns into thread_switch in process 2's stack (we switch threads in the middle of the execution of switchframe_switch). Implementation is found in `switch.S`.



### Scheduling

* If 0 threads are runnable, then halt CPU
* If 1 thread is runnable, then run the thread
* If 2+ threads are runnable, make a scheduling decision.  We could scan the process table, use FIFO/Round-Robin (this is used in OS161) or use priorities.

To demonstrate FIFO, consider thread $A$, $B$, and $C$ (in this order) and suppose $A$ gets to run until it is finished. According to this system, $B$ then gets to run until it is finished, then $C$ gets to run until it is finished.

Round-Robin is just FIFO but with preemption introduced. So, $A$ runs for a bit then is kicked out. Then, $A$ is placed at the end of the queue and $B$ runs for a bit. Then, $B$ is kicked out, placed at the end of the queue, and $C$ runs for a bit. Now, when $C$ is kicked off, we will run $A$.



## Threads

Recall that threads is a schedulable execution context (progam counter, registers, stack, etc.). We can have multi-threaded programs where the address space is shared.

For example, considering running a function $foo(arr[i])$ on every int in $arr[20000000000]$, where $foo(arr[i])$ is independent. Instead of forking processes, we can create threads instead. However, switching between the processes will be *very* expensive. Instead, we can create additional threads for a process. Because they share the same process, they share the same memory (the only real difference is the stack).

The threads have a user stack as well as a kernel stack.

The POSIX thread API provides us functions to dealing with threads.

### `int pthread_create(pthread_t *thr, pthread_attr_t *attr, void *(*f(n)(void *), void *arg))`

Creates a new thread identified by `thr` with optional attributes, run `fn` with `arg`. Note that we need `void` pointers here because the function `fn` could consume any data and return any data. We will need to perform casting.

### `void pthread_exit(void *return_value)`

Destroy the current thread and returns a pointer. This pointer is the return value of the function and is not to be confused with the exit status for processes.

### `int pthread_join(pthread_t thread, void **return_value)`

Wait for thread `thread` to exit and receive the return value.

### `void pthread_yield()`

Tell the OS scheduler to run another thread or process. In OS161, this is `thread_yield`. When threads are interrupted, it is pretty much the same as the prior stack example for processes but without the thread data.



Example:

```c
volatile int counter = 0;
void* increaseCounter(void *s) {
    cout << "Begin: ";
    cout << *((char *)s);
    cout << endl;
    for (int i = 0; i < 10000000; i++) {
        counter = counter + 1;
    }
    cout << "Done: " << *((char *)s) << endl;
}

int main() {
    pthread_t t1, t2;
    char t1Name = 'A';
    char t2Name = 'B';
    int rc;
    rc = pthread_create(&t2, NULL, increaseCounter, (void *) &t1Name);
    if (rc) {
        cout << "Error Creating Thread" << endl;
        exit(-1);
    }
    rc = pthread_create(&t2, NULL, increaseCounter, (void *) &t2Name);
    if (rc) {
        cout << "Error Creating Thread" << endl;
        exit(-1);
    }
    rc = pthread_join(t1, NULL);
    rc = pthread_join(t2, NULL);
    cout << "Counter = " << counter << endl;
    pthread_exit(NULL);
}
```
The output for this code is not guaranteed to be 20000000. In fact, it will *almost* never be 20000000. If we want to share data, we have to be careful in how we do it. We need to make sure that mutations of shared data does not occur at the same time.

```mips
t7 - counter value
t8 - address of counter variable

lw t7 0(t8)
add1 t7 t7 1
sw t7 O(t8)
```
Here, we have a serious problem with overwriting values - threads are capable of destroying the work of other threads.

To add `pthread_create`:
1. Start with process abstraction in the kernel
2. Modify process creation to keep same address space, file table, etc. as well as let `clone` syscalls allow individual control

Any multi-threaded programs using kernel threads will require heavy utilization of the kernel which is expensive, but allows threads to ultimately utilize more than one CPU core. An alternative is to implement user-level threads with one main kernel thread per process. To implement user-threads:

1. Allocate a new stack for each `pthread_create`
2. Keep a queue of runnable threads
3. Replace blocking system calls
4. Schedule periodic timer signal (switch to other threads on timer signals)

User threads cannot take advantage of multiple CPUs or cores (unless we utilize a `n:m` scheme where `m` kernel threads have `n` user threads), however, and a blocking system call will block all user-level threads. We also have concerns with deadlock (TBD in the future). This is because kernels do not know anything about user threads, only kernel threads.

There are some limitations of `n:m` threading, which include:
* Possible blocked threads and deadlock
* Difficult to keep track of available CPUs
* Kernel cannot know relative importance of threads

Ultimately, the lessons learnt with threading are:

1. Threads are best implemented as a library separate from kernel threads
2. We can still utilize threads, and it's still recommended to use kernel threads for `I/O` concurrency and `n:m` threads for highly concurrent applications with many thread switches
3. Concurrency and synchronization (especially with regards to threads) will greatly increase the complexity of a program

We want more threads than cores so each core still has a particular task. Furthermore, multi-threading loses purpose once the number of threads we create exceeds the number of threads a CPU provides.

### OS161 Threads

* Registers will need to be divided into 2 groups. Functions are free to clobber caller-saved registers (t0-t9) but must restore callee-saved ones to original value upon return (s0-s7, fp)
* the sp register will always be the base of the stack.
* local variables stored in registers and on stack
* function arguments go into caller-saved regs and on stack (a0-a3)
* return value is v0 and v1

If `foo` calls `bar`, then `foo` first needs to save active caller registers then call `bar`. Then, `bar` saves the used callee registers, does what it's supposed to do, restore the callee registers, and jumps back to `foo`, which will restore the caller registers.

* Return address, caller-saved registers are saved on the stack
* Callee-saved regs, global variables, and stack pointers are not saved

Threads vs Procedures: Threads may resume out of order (one stack per thread), threads switch less often, threads can be involuntarily interrupted, and more than one thread can run at a time.

In OS161, we have `fork, exec, exit`, and `wait` where we have one thread per process. Additionally, we do not have any user-level threading - each program only gets one kernel thread. We can create kernel threads with `thread_fork()` (bad naming, this isn't actually a fork) In order for a process to run, we need to give it a thread. All thread switches go through `thread_yield()` and `thread_switch()`.







 

# Synchronization

Recall that:
* A process is an instance of a running program with one or more threads
* A thread is an execution context (share address space, open file cursors, have their own CPU registers and stack)
* We have POSIX Thread APIs for thread creation, deletion, and joining.

With the example shown in the threading section, we can see a data race where two threads compete to change data with respect to themselves rather than the intended program at large. Even a naive implementation like the following does **not** completely solve this problem:

```c
#define NUM_THREADS 2
volatile int counter = 0;
bool counterLock = false;

void* increaseCounter(void *s) {
    cout << "Begin: ":
    cout << *((char *)s);
    cout << endl;
    for (int i = 0; i < 10000000; ++i>) {
        while (counterLock) {}
        counterLock = true;
        counter = counter + 1;
        counterLock = false;
    }
}
```

We need synchronization to resolve this problem. Some options to solve this include atomic instructions (impractical), and locks (a basic global variable is not enough). 

Sequential consistency: the result of execution is as if all operations were executed in some sequential order, and the operations of each processor occurred in the order specified by the program. Note that not all CPUs have sequential consistency because it negatively affects optimizations and complicates buffering, re-ordering, reads, and cache coherence.

x86 atomicity: `lock`, `xchg` (exchange register/memory with register - seeing previous value can help with synchronization) `cmpxchg`, and `lfence/sfence/mfence`

Producer/Consumer code assuming we have sequential consistency:

```c
// buffer stores buffer-size items
// count is number of used slots
// out is next empty buffer slot to fill (if any)
// in is oldest filled slot to consume (if any)

void producer (void *ignored) {
    for (;;) {
        item *nextProduces = produce_item();
        while (count == BUFFER_SIZE) {}
        buffer [in] = nextProduced;
        in = (in + 1) % BUFFER_SIZE;
    }
}

void consumer (void *ignored) {
    for (;;) {
        while (count == 0) {}
        item *nextConsumed = buffer[out];
        out = (out + 1) % BUFFER_SIZE;
        count--;
        consume_item(nextConsumed)
    }
}

```

What we want are:

* Mutual Exclusion (only one thread can be in critical section at a time)
* Progress (a process will eventually get in a critical section)
* Bounded waiting (a bound on the number of times other threads get in)